{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwYPjcGYs62B7Dm8IDcHUu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArmaanSeth/Langchain/blob/main/LangGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drjERiTFyE3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98aaf97-ca7f-498f-fc4c-d8c6009748ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.0/817.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchainhub langgraph langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
        "\n",
        "llm=ChatGoogleGenerativeAI(model='gemini-pro', convert_system_message_to_human=True, google_api_key=userdata.get('GOOGLE_API_KEY'), verbose=True)"
      ],
      "metadata": {
        "id": "e7NEge9v4mH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union, List, Annotated, TypedDict\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langchain_core.messages import BaseMessage\n",
        "import operator"
      ],
      "metadata": {
        "id": "wESwx6jX5IE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "  input: str\n",
        "  chat_history:list[BaseMessage]\n",
        "  agent_outcome: Union[AgentAction, AgentFinish, None]\n",
        "  # return_direct: bool\n",
        "  intermediate_steps: Annotated[list[tuple[AgentAction,str]], operator.add]"
      ],
      "metadata": {
        "id": "sXQp-uWM5jH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import BaseTool, StructuredTool, Tool, tool"
      ],
      "metadata": {
        "id": "yDZMSYpsAm2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class to_lower_case(BaseTool):\n",
        "  name=\"lower_case\"\n",
        "  description=\"This tool returns the input as all lower case. Input: should be a string of alphabets in uppercase\"\n",
        "  def _run(self, input:str) ->str :\n",
        "    return input.lower()\n",
        "\n",
        "class random_number(BaseTool):\n",
        "    name=\"random_number\"\n",
        "    description=\"This tool returns a random number in digits. Input: should be an empty string\"\n",
        "    def _run(self, input:str) -> int:\n",
        "      return random.randint(0, 100)\n",
        "\n",
        "tools = [to_lower_case(),random_number()]"
      ],
      "metadata": {
        "id": "0YqwbSnpJSUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_number._run(random_number,input='')"
      ],
      "metadata": {
        "id": "goLAhbwYJUKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_lower_case._run(to_lower_case,input=\"23\")"
      ],
      "metadata": {
        "id": "bzFNN66IJVpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template=\"\"\"\n",
        "Answer the following questions as best you can.\n",
        "Question:{input}\n",
        "\n",
        "You have access to the following tools but you can also choose not to use any tool:\n",
        "\n",
        "{tools}\n",
        "\n",
        "To answer the question break the question into smaller task the repeatedly use the below startegy to get the final answer\n",
        "Use the following format:\n",
        "\n",
        "Question: what should be done at the moment to make the current answer more suitable for question\n",
        "Thought: you should always think about what to do. If there is no need to use any tool, simply generate your answer and skip the use of any tool at the moment.\n",
        "Action: what action to choose from [{tool_names}],it shouold only be the name without ().\n",
        "Action Input: According to the next action's description, modify the information to be the input to the tool\n",
        "Observation:The output from action is used to update the current answer.Is the updated answer, the final answer? If not repeat the above steps with same or different tools\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "Thought:{agent_scratchpad}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
        "                        template=template)"
      ],
      "metadata": {
        "id": "c6gTX6pVdGMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import create_react_agent\n",
        "from langchain_core.agents import AgentActionMessageLog\n",
        "\n",
        "agent_runnable = create_react_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "jZl8t8xpJXx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"give me a random number and then write in words and make it lower case.\"}\n",
        "\n",
        "agent_outcome = agent_runnable.invoke(inputs)"
      ],
      "metadata": {
        "id": "O4QGElj1J1rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"give me a random number and then write in words and make it lower case.\",\n",
        "          \"chat_history\": [],\n",
        "          \"intermediate_steps\":[]}\n",
        "\n",
        "agent_outcome = agent_runnable.invoke(inputs)\n",
        "agent_outcome"
      ],
      "metadata": {
        "id": "iGWzAfo1stzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_outcome"
      ],
      "metadata": {
        "id": "lKKiYp8dKGpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.template)"
      ],
      "metadata": {
        "id": "SNqoPCV7Rmg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
        "\n",
        "tool_executor=ToolExecutor(tools)"
      ],
      "metadata": {
        "id": "OzDJZ5xcK8V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent(data):\n",
        "    agent_outcome = agent_runnable.invoke(data)\n",
        "    return {\"agent_outcome\": agent_outcome}\n",
        "\n",
        "def execute_tools(data):\n",
        "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
        "    agent_action = data[\"agent_outcome\"]\n",
        "    output = tool_executor.invoke(agent_action)\n",
        "    print(f\"The agent action is {agent_action}\")\n",
        "    print(f\"The tool result is: {output}\")\n",
        "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
        "\n",
        "def should_continue(data):\n",
        "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    if isinstance(data[\"agent_outcome\"], AgentFinish):\n",
        "        return \"end\"\n",
        "    # Otherwise, an AgentAction is returned\n",
        "    # Here we return `continue` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    else:\n",
        "        return \"continue\""
      ],
      "metadata": {
        "id": "G2aqupJMLipg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph .graph import END, StateGraph\n",
        "\n",
        "workflow=StateGraph(AgentState)\n",
        "workflow.add_node(\"agent\", run_agent)\n",
        "workflow.add_node(\"action\", execute_tools)\n",
        "workflow.set_entry_point(\"agent\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue,\n",
        "    {\n",
        "        'continue':'action',\n",
        "        'end':END\n",
        "    }\n",
        ")\n",
        "workflow.add_edge('action', 'agent')\n",
        "app=workflow.compile()"
      ],
      "metadata": {
        "id": "gRppXXL3MEM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"give me a random number and then write in words and make it lower case.\", \"chat_history\":[]}\n",
        "for s in app.stream(inputs):\n",
        "    print(list(s.values())[0])\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "id": "OAOFgGfuNvgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"give me a random number and then write in words and make it lower case\", \"chat_history\": []}\n",
        "\n",
        "res=app.invoke(inputs)"
      ],
      "metadata": {
        "id": "liTjAfv1quqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res[\"agent_outcome\"].return_values['output']"
      ],
      "metadata": {
        "id": "O50lo3jt9OAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"Explain is AI?\", \"chat_history\": []}\n",
        "\n",
        "res=app.invoke(inputs)"
      ],
      "metadata": {
        "id": "oBOUT-Jh9dTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res[\"agent_outcome\"].return_values['output']"
      ],
      "metadata": {
        "id": "UrYNLAvGGbJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uF-aN3LKGkff"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}